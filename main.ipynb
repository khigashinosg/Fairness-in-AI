{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import folktables\n",
    "from folktables import ACSDataSource\n",
    "import numpy as np\n",
    "from custom_functions import *\n",
    "from aif360.datasets import StandardDataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aif360.metrics import ClassificationMetric\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup Code (from Spec Sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyhi2018/Desktop/Imperial/Ethics, Fairness, and Explainability in AI/CW1 - Fairness/Fairness-in-AI/venv/lib/python3.11/site-packages/aif360/datasets/standard_dataset.py:143: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[pos, label_name] = favorable_label\n"
     ]
    }
   ],
   "source": [
    "# (Age) must be greater than 16 and less than 90,\n",
    "# and (Person weight) must be greater than or equal to 1\n",
    "def employment_filter(data):\n",
    "    \"\"\"Filters for the employment prediction task\"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['AGEP'] < 90]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    return df\n",
    "\n",
    "ACSEmployment = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',  # age; for range of values of features please check Appendix B.4 of Retiring Adult: New Datasets for Fair Machine Learning NeurIPS 2021 paper\n",
    "        'SCHL',  # educational attainment\n",
    "        'MAR',   # marital status\n",
    "        'RELP',  # relationship\n",
    "        'DIS',   # disability recode\n",
    "        'ESP',   # employment status of parents\n",
    "        'CIT',   # citizenship status\n",
    "        'MIG',   # mobility status (lived here 1 year ago)\n",
    "        'MIL',   # military service\n",
    "        'ANC',   # ancestry recode\n",
    "        'NATIVITY',  # nativity\n",
    "        'DEAR',   # hearing difficulty\n",
    "        'DEYE',   # vision difficulty\n",
    "        'DREM',   # cognitive difficulty\n",
    "        'SEX',    # sex\n",
    "        'RAC1P',  # recoded detailed race code\n",
    "        'GCL',    # grandparents living with grandchildren\n",
    "    ],\n",
    "    target='ESR',  # employment status recode\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='DIS',\n",
    "    preprocess=employment_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"FL\"], download=True)  # data for Florida state\n",
    "\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "\n",
    "data = pd.DataFrame(features, columns=ACSEmployment.features)\n",
    "data['label'] = label\n",
    "\n",
    "favorable_classes = [True]\n",
    "protected_attribute_names = [ACSEmployment.group]\n",
    "privileged_classes = np.array([[1]])\n",
    "\n",
    "data_for_aif = StandardDataset(\n",
    "    data,\n",
    "    label_name='label',\n",
    "    favorable_classes=favorable_classes,\n",
    "    protected_attribute_names=protected_attribute_names,\n",
    "    privileged_classes=privileged_classes\n",
    ")\n",
    "\n",
    "privileged_groups = [{'DIS': 1}]\n",
    "unprivileged_groups = [{'DIS': 2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reweight = False\n",
      "Training model with C = 1e-06 and solver = newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyhi2018/Desktop/Imperial/Ethics, Fairness, and Explainability in AI/CW1 - Fairness/Fairness-in-AI/custom_functions.py:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with C = 1e-06 and solver = lbfgs\n",
      "Training model with C = 1e-06 and solver = liblinear\n",
      "Training model with C = 1e-06 and solver = sag\n",
      "Training model with C = 1e-06 and solver = saga\n",
      "Training model with C = 1e-05 and solver = newton-cg\n",
      "Training model with C = 1e-05 and solver = lbfgs\n",
      "Training model with C = 1e-05 and solver = liblinear\n",
      "Training model with C = 1e-05 and solver = sag\n",
      "Training model with C = 1e-05 and solver = saga\n",
      "Training model with C = 0.0001 and solver = newton-cg\n",
      "Training model with C = 0.0001 and solver = lbfgs\n",
      "Training model with C = 0.0001 and solver = liblinear\n",
      "Training model with C = 0.0001 and solver = sag\n",
      "Training model with C = 0.0001 and solver = saga\n",
      "Training model with C = 0.001 and solver = newton-cg\n",
      "Training model with C = 0.001 and solver = lbfgs\n",
      "Training model with C = 0.001 and solver = liblinear\n",
      "Training model with C = 0.001 and solver = sag\n",
      "Training model with C = 0.001 and solver = saga\n",
      "Training model with C = 0.01 and solver = newton-cg\n",
      "Training model with C = 0.01 and solver = lbfgs\n",
      "Training model with C = 0.01 and solver = liblinear\n",
      "Training model with C = 0.01 and solver = sag\n",
      "Training model with C = 0.01 and solver = saga\n",
      "Training model with C = 0.1 and solver = newton-cg\n",
      "Training model with C = 0.1 and solver = lbfgs\n",
      "Training model with C = 0.1 and solver = liblinear\n",
      "Training model with C = 0.1 and solver = sag\n",
      "Training model with C = 0.1 and solver = saga\n",
      "Training model with C = 1 and solver = newton-cg\n",
      "Training model with C = 1 and solver = lbfgs\n",
      "Training model with C = 1 and solver = liblinear\n",
      "Training model with C = 1 and solver = sag\n",
      "Training model with C = 1 and solver = saga\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train-val and test sets\n",
    "train_and_val_data_2, test_data_1 = data_for_aif.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "# Apply grid search and randomised train-val splits, saving all results and exporting best models\n",
    "task_1_results = grid_search_models(train_and_val_data_2, custom_criterion_style='sum_of_logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:\n",
      "        C Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "21  0.01  lbfgs       0.751253  0.615774              -1.243065 \n",
      "\n",
      "Best EOD:\n",
      "           C     Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "0  0.000001  newton-cg       0.542484  0.019263              -0.631057\n",
      "1  0.000001      lbfgs       0.542262  0.019263              -0.631466\n",
      "4  0.000001       saga       0.542390  0.019263              -0.631230 \n",
      "\n",
      "Lowest non-zero EOD:\n",
      "           C     Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "0  0.000001  newton-cg       0.542484  0.019263              -0.631057\n",
      "1  0.000001      lbfgs       0.542262  0.019263              -0.631466\n",
      "4  0.000001       saga       0.542390  0.019263              -0.631230 \n",
      "\n",
      "Best criterion:\n",
      "           C     Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "0  0.000001  newton-cg       0.542484  0.019263              -0.631057 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the best model\n",
    "best_accuracy_1, best_eod_1, best_nonzero_eod_1, best_cc_1 = find_best_results(task_1_results)\n",
    "\n",
    "# Prine results\n",
    "print(f\"Best accuracy:\\n\", best_accuracy_1, f'\\n')\n",
    "print(f\"Best EOD:\\n\", best_eod_1, f'\\n')\n",
    "print(f\"Lowest non-zero EOD:\\n\", best_nonzero_eod_1, f'\\n')\n",
    "print(f\"Best criterion:\\n\", best_cc_1, f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Held-out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most accurate model:\n",
      "Accuracy: 0.7523310487727127\n",
      "EOD: 0.6736529561484942 \n",
      "\n",
      "Custom criterion: 0.6725043999780665\n",
      "Best EOD model:\n",
      "Accuracy: 0.541819413452343\n",
      "EOD: 0.01934235976789167\n",
      "Custom criterion: 1.2552576841394483\n",
      "Best CC model:\n",
      "Accuracy: 0.525880618425247\n",
      "EOD: 0.0 \n",
      "\n",
      "Custom criterion: 1.2765504248353203\n"
     ]
    }
   ],
   "source": [
    "# Metrics for both the best accuracy and best EOD models\n",
    "best_accuracy_accuracy_1, best_accuracy_eod_1, best_accuracy_cc_1 = test_model(test_data_1, 'std_model_accuracy.joblib')\n",
    "best_eod_accuracy_1, best_eod_eod_1, best_eod_cc_1 = test_model(test_data_1, 'std_model_eod.joblib')\n",
    "best_cc_accuracy_1, best_cc_eod_1, best_cc_cc_1 = test_model(test_data_1, 'std_model_cc.joblib')\n",
    "\n",
    "# Print results\n",
    "print(\"Most accurate model:\")\n",
    "print(f\"Accuracy: {best_accuracy_accuracy_1}\")\n",
    "print(f\"EOD: {best_accuracy_eod_1}\", f'\\n')\n",
    "print(f\"Custom criterion: {best_accuracy_cc_1}\")\n",
    "\n",
    "print(\"Best EOD model:\")\n",
    "print(f\"Accuracy: {best_eod_accuracy_1}\")\n",
    "print(f\"EOD: {best_eod_eod_1}\")\n",
    "print(f\"Custom criterion: {best_eod_cc_1}\")\n",
    "\n",
    "print(\"Best CC model:\")\n",
    "print(f\"Accuracy: {best_cc_accuracy_1}\")\n",
    "print(f\"EOD: {best_cc_eod_1}\", f'\\n')\n",
    "print(f\"Custom criterion: {best_cc_cc_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reweight = True\n",
      "Training model with C = 1e-06 and solver = newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyhi2018/Desktop/Imperial/Ethics, Fairness, and Explainability in AI/CW1 - Fairness/Fairness-in-AI/custom_functions.py:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with C = 1e-06 and solver = lbfgs\n",
      "Training model with C = 1e-06 and solver = liblinear\n",
      "Training model with C = 1e-06 and solver = sag\n",
      "Training model with C = 1e-06 and solver = saga\n",
      "Training model with C = 1e-05 and solver = newton-cg\n",
      "Training model with C = 1e-05 and solver = lbfgs\n",
      "Training model with C = 1e-05 and solver = liblinear\n",
      "Training model with C = 1e-05 and solver = sag\n",
      "Training model with C = 1e-05 and solver = saga\n",
      "Training model with C = 0.0001 and solver = newton-cg\n",
      "Training model with C = 0.0001 and solver = lbfgs\n",
      "Training model with C = 0.0001 and solver = liblinear\n",
      "Training model with C = 0.0001 and solver = sag\n",
      "Training model with C = 0.0001 and solver = saga\n",
      "Training model with C = 0.001 and solver = newton-cg\n",
      "Training model with C = 0.001 and solver = lbfgs\n",
      "Training model with C = 0.001 and solver = liblinear\n",
      "Training model with C = 0.001 and solver = sag\n",
      "Training model with C = 0.001 and solver = saga\n",
      "Training model with C = 0.01 and solver = newton-cg\n",
      "Training model with C = 0.01 and solver = lbfgs\n",
      "Training model with C = 0.01 and solver = liblinear\n",
      "Training model with C = 0.01 and solver = sag\n",
      "Training model with C = 0.01 and solver = saga\n",
      "Training model with C = 0.1 and solver = newton-cg\n",
      "Training model with C = 0.1 and solver = lbfgs\n",
      "Training model with C = 0.1 and solver = liblinear\n",
      "Training model with C = 0.1 and solver = sag\n",
      "Training model with C = 0.1 and solver = saga\n",
      "Training model with C = 1 and solver = newton-cg\n",
      "Training model with C = 1 and solver = lbfgs\n",
      "Training model with C = 1 and solver = liblinear\n",
      "Training model with C = 1 and solver = sag\n",
      "Training model with C = 1 and solver = saga\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train-val and test sets\n",
    "train_and_val_data_2, test_data_2 = data_for_aif.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "# Apply grid search and randomised train-val splits, saving all results and exporting best models\n",
    "task_2_results = grid_search_models(train_and_val_data_2, reweight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:\n",
      "         C     Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "15  0.001  newton-cg        0.72007 -0.018474               1.482009\n",
      "19  0.001       saga        0.72007 -0.018457               1.482043 \n",
      "\n",
      "Best EOD:\n",
      "        C Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "24  0.01   saga       0.719925 -0.022143                1.47458 \n",
      "\n",
      "Lowest non-zero EOD:\n",
      "         C Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "18  0.001    sag       0.720036 -0.018224               1.482447 \n",
      "\n",
      "Best criterion:\n",
      "         C Solver  Mean accuracy  Mean EOD  Mean custom criterion\n",
      "18  0.001    sag       0.720036 -0.018224               1.482447 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the best results\n",
    "best_accuracy_2, best_eod_2, best_nonzero_eod_2, best_cc_2 = find_best_results(task_2_results)\n",
    "\n",
    "# Print results analysis\n",
    "print(f\"Best accuracy:\\n\", best_accuracy_2, f'\\n')\n",
    "print(f\"Best EOD:\\n\", best_eod_2, f'\\n')\n",
    "print(f\"Lowest non-zero EOD:\\n\", best_nonzero_eod_2, f'\\n')\n",
    "print(f\"Best criterion:\\n\", best_cc_2, f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Held-out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most accurate model:\n",
      "Accuracy: 0.7197760599298693\n",
      "EOD: 0.004663503874752228 \n",
      "\n",
      "Custom criterion: 1.5087723169670522\n",
      "Best EOD model:\n",
      "Accuracy: 0.525880618425247\n",
      "EOD: 0.0\n",
      "Custom criterion: 1.2765504248353203\n",
      "Best CC model:\n",
      "Accuracy: 0.7209316225693337\n",
      "EOD: 0.03690541551817195 \n",
      "\n",
      "Custom criterion: 1.4472935830786773\n",
      "Most accurate model:\n",
      "Accuracy: 0.7197760599298693\n",
      "EOD: 0.004663503874752228 \n",
      "\n",
      "Best EOD model:\n",
      "Accuracy: 0.525880618425247\n",
      "EOD: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Metrics for both the best accuracy and best EOD models\n",
    "best_accuracy_accuracy_2, best_accuracy_eod_2, best_accuracy_cc_2 = test_model(test_data_2, 'fair_model_accuracy.joblib')\n",
    "best_eod_accuracy_2, best_eod_eod_2, best_eod_cc_2 = test_model(test_data_2, 'fair_model_eod.joblib')\n",
    "best_cc_accuracy_2, best_cc_eod_2, best_cc_cc_2 = test_model(test_data_2, 'fair_model_cc.joblib')\n",
    "\n",
    "# Print results\n",
    "print(\"Most accurate model:\")\n",
    "print(f\"Accuracy: {best_accuracy_accuracy_2}\")\n",
    "print(f\"EOD: {best_accuracy_eod_2}\", f'\\n')\n",
    "print(f\"Custom criterion: {best_accuracy_cc_2}\")\n",
    "\n",
    "print(\"Best EOD model:\")\n",
    "print(f\"Accuracy: {best_eod_accuracy_2}\")\n",
    "print(f\"EOD: {best_eod_eod_2}\")\n",
    "print(f\"Custom criterion: {best_eod_cc_2}\")\n",
    "\n",
    "print(\"Best CC model:\")\n",
    "print(f\"Accuracy: {best_cc_accuracy_2}\")\n",
    "print(f\"EOD: {best_cc_eod_2}\", f'\\n')\n",
    "print(f\"Custom criterion: {best_cc_cc_2}\")\n",
    "# Print results\n",
    "print(\"Most accurate model:\")\n",
    "print(f\"Accuracy: {best_accuracy_accuracy_2}\")\n",
    "print(f\"EOD: {best_accuracy_eod_2}\", f'\\n')\n",
    "print(\"Best EOD model:\")\n",
    "print(f\"Accuracy: {best_eod_accuracy_2}\")\n",
    "print(f\"EOD: {best_eod_eod_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
