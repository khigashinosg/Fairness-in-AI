{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Setup Code (from Spec Sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyhi2018/Desktop/Imperial/Ethics, Fairness, and Explainability in AI/CW1 - Fairness/Fairness-in-AI/venv/lib/python3.11/site-packages/aif360/datasets/standard_dataset.py:143: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[pos, label_name] = favorable_label\n"
     ]
    }
   ],
   "source": [
    "from folktables import folktables\n",
    "from folktables import ACSDataSource\n",
    "import numpy as np\n",
    "\n",
    "# (Age) must be greater than 16 and less than 90,\n",
    "# and (Person weight) must be greater than or equal to 1\n",
    "def employment_filter(data):\n",
    "    \"\"\"Filters for the employment prediction task\"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['AGEP'] < 90]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    return df\n",
    "\n",
    "ACSEmployment = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',  # age; for range of values of features please check Appendix B.4 of Retiring Adult: New Datasets for Fair Machine Learning NeurIPS 2021 paper\n",
    "        'SCHL',  # educational attainment\n",
    "        'MAR',   # marital status\n",
    "        'RELP',  # relationship\n",
    "        'DIS',   # disability recode\n",
    "        'ESP',   # employment status of parents\n",
    "        'CIT',   # citizenship status\n",
    "        'MIG',   # mobility status (lived here 1 year ago)\n",
    "        'MIL',   # military service\n",
    "        'ANC',   # ancestry recode\n",
    "        'NATIVITY',  # nativity\n",
    "        'DEAR',   # hearing difficulty\n",
    "        'DEYE',   # vision difficulty\n",
    "        'DREM',   # cognitive difficulty\n",
    "        'SEX',    # sex\n",
    "        'RAC1P',  # recoded detailed race code\n",
    "        'GCL',    # grandparents living with grandchildren\n",
    "    ],\n",
    "    target='ESR',  # employment status recode\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='DIS',\n",
    "    preprocess=employment_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"FL\"], download=True)  # data for Florida state\n",
    "\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(features, columns=ACSEmployment.features)\n",
    "data['label'] = label\n",
    "\n",
    "favorable_classes = [True]\n",
    "protected_attribute_names = [ACSEmployment.group]\n",
    "privileged_classes = np.array([[1]])\n",
    "\n",
    "data_for_aif = StandardDataset(\n",
    "    data,\n",
    "    label_name='label',\n",
    "    favorable_classes=favorable_classes,\n",
    "    protected_attribute_names=protected_attribute_names,\n",
    "    privileged_classes=privileged_classes\n",
    ")\n",
    "\n",
    "privileged_groups = [{'DIS': 1}]\n",
    "unprivileged_groups = [{'DIS': 2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7481962173931606\n",
      "{'stat_par_diff': 0.5933665124477165, 'eq_opp_diff': 0.6025930026276827, 'avg_odds_diff': 0.49263644954306124, 'bal_acc': 0.7457300442774388, 'disp_imp': 9.355185504501474}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Split the dataset into train-val and test sets\n",
    "train_and_val_data, test_data = data_for_aif.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "# Split train-val set into train and val sets\n",
    "train_data, val_data = train_and_val_data.split([0.8], shuffle=True, seed=0)\n",
    "\n",
    "# Normalize the train and val datasets\n",
    "scale_orig = StandardScaler()\n",
    "x_train = scale_orig.fit_transform(train_data.features)\n",
    "y_train = train_data.labels.ravel()\n",
    "x_val = scale_orig.fit_transform(val_data.features)\n",
    "y_val = val_data.labels.ravel()\n",
    "\n",
    "# Model\n",
    "learner = LogisticRegression(solver='liblinear', random_state=0)\n",
    "learner.fit(x_train,y_train)\n",
    "predictions = learner.predict(x_val)\n",
    "\n",
    "val_pred = val_data.copy()\n",
    "val_pred.labels = predictions\n",
    "print(\"Accuracy\", sum(predictions==y_val)/len(y_val))\n",
    "\n",
    "metric = ClassificationMetric(val_data, val_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "metric_arrs = {}\n",
    "#Statistical Parity Difference measures the difference of the above values instead of ratios, hence we\n",
    "#would like it to be close to 0.\n",
    "metric_arrs['stat_par_diff']=(metric.statistical_parity_difference())\n",
    "#Equal opportunity difference measures the ability of the classifier to accurately classify a datapoint as positive\n",
    "#regardless of the presence of the unpriviliged feature. We would like it to be close to 0. A negative value signals bias\n",
    "#towards priviliged.\n",
    "metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
    "#Average of difference in FPR and TPR for unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
    "#Balanced accuracy is a general metric, not dependent on bias. We would like to have it close to 1, meaning\n",
    "#that the classifier can equally detect positive and negative classes.\n",
    "metric_arrs['bal_acc']=((metric.true_positive_rate() + metric.true_negative_rate()) / 2)\n",
    "#We would like Disparate Impact to be close to 1. It measures the ratio between the likelihood of the class being\n",
    "#predicted as positive if we have the unpriviliged feature and the the same likelihood with the priviliged feature.\n",
    "#Values close to 0 indicate strong bias.\n",
    "metric_arrs['disp_imp']=(metric.disparate_impact())\n",
    "print(metric_arrs)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
